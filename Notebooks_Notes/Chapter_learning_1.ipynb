{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Chapter_learning_1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"kqgO3gGLEL-c","colab_type":"code","colab":{},"outputId":"ebd5cae4-7ba0-489d-9d55-784aedbc5dbb"},"source":["import pymc3 as pm\n","#Generative model\n","#we select probabilities for the six faces\n","theta = [0.1,0.2,0.2,0.2,0.2,0.1]\n","#we define a probabilistic model\n","dice = pm.Categorical.dist(theta)\n","print(\">\",dice.random())\n","print(\">\",dice.random())    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["> 0\n","> 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9NmtYWoKEL-g","colab_type":"code","colab":{},"outputId":"71716516-562f-4503-8469-bd07bac94d2b"},"source":["import numpy as np\n","#Possibility space of two rolls\n","Omega=[(i,j) for i in range(1,7) for j in range(1,7)]\n","#we select probabilities for the six faces\n","theta = np.array([0.1,0.2,0.2,0.2,0.2,0.1])\n","theta_2=np.kron(theta,theta)#this computes all possible products\n","print(\">\",theta_2)\n","#we define a probabilistic model\n","dice = pm.Categorical.dist(theta_2)\n","print(\">\",Omega[dice.random()])#result of one roll\n","print(\">\",Omega[dice.random()])#result of another roll"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> [0.01 0.02 0.02 0.02 0.02 0.01 0.02 0.04 0.04 0.04 0.04 0.02 0.02 0.04\n"," 0.04 0.04 0.04 0.02 0.02 0.04 0.04 0.04 0.04 0.02 0.02 0.04 0.04 0.04\n"," 0.04 0.02 0.01 0.02 0.02 0.02 0.02 0.01]\n","> (3, 3)\n","> (2, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ECDuoq_bEL-j","colab_type":"code","colab":{},"outputId":"41b25e34-e215-476d-9438-a36366245d88"},"source":["#we select probabilities for the six faces\n","theta = np.array([0.1,0.2,0.2,0.2,0.2,0.1])\n","#we define a probabilistic model\n","dice = pm.Multinomial.dist(100,theta)\n","print(\">\",dice.random())#result of 100 rolls\n","print(\">\",dice.random())#result of other 100 rolls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> [15. 13. 16. 17. 26. 13.]\n","> [ 8. 18. 17. 22. 24. 11.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7rHlb0ILEL-m","colab_type":"code","colab":{},"outputId":"4df2a6d9-db8d-4ca1-e50b-ed584bb5cbd4"},"source":["np.prod(theta**([15., 13., 16., 17., 26., 13.]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.7223664828696717e-79"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"bwMHVeEqEL-o","colab_type":"code","colab":{},"outputId":"93965414-df3d-499c-d74f-1c9c49ef8057"},"source":["np.sum(np.log(theta**([15., 13., 16., 17., 26., 13.])))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-180.3519122990885"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"kfp78XfnEL-r","colab_type":"text"},"source":["## Map estimate"]},{"cell_type":"code","metadata":{"id":"_D4NNzpbEL-r","colab_type":"code","colab":{},"outputId":"1e168d97-10fb-484b-f093-0dad042c6790"},"source":["#we select probabilities for the six faces\n","theta = np.array([0.1,0.2,0.2,0.2,0.2,0.1])\n","#we define a probabilistic model\n","dice = pm.Multinomial.dist(100,theta)\n","data=dice.random()\n","print(data)#counts for 100 rolls\n","print(\"MLE=\",data/np.sum(data))\n","#no we throws the dice 10000 times\n","dice = pm.Multinomial.dist(100000,theta)\n","data=dice.random()\n","print(data)#counts for 100000 rolls\n","print(\"MLE=\",data/np.sum(data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[13. 17. 19. 27. 17.  7.]\n","MLE= [0.13 0.17 0.19 0.27 0.17 0.07]\n","[10105. 19843. 20176. 19844. 19933. 10099.]\n","MLE= [0.10105 0.19843 0.20176 0.19844 0.19933 0.10099]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9o5BOL7FEL-t","colab_type":"code","colab":{},"outputId":"a4abb816-2cd8-495d-aa77-0fe1339e9a7d"},"source":["counts = np.array([15, 32, 16, 17, 26, 26])\n","alpha = np.ones(len(counts),float)\n","with pm.Model() as model:\n","    theta=pm.Dirichlet(\"theta\",alpha)\n","    data =pm.Multinomial(\"likelihood\",np.sum(counts),theta,observed=counts)\n","#MAP estimate analytical formula\n","MAP=(counts+alpha)/np.sum(counts+alpha)\n","#we can also do it numerically\n","map_estimate = pm.find_MAP(model=model)\n","print(MAP,map_estimate['theta'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["logp = -11.992, ||grad|| = 13.657: 100%|██████████| 9/9 [00:00<00:00, 2706.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["[0.11594203 0.23913043 0.12318841 0.13043478 0.19565217 0.19565217] [0.11363636 0.24242425 0.12121209 0.1287879  0.1969697  0.1969697 ]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Goo9MfjlEL-w","colab_type":"code","colab":{},"outputId":"56dfd387-cd29-4f33-81b8-fbfbd42cf6e9"},"source":["#we select probabilities for the six faces\n","theta = np.array([0.1,0.2,0.2,0.2,0.2,0.1])\n","#we define a probabilistic model\n","dice = pm.Multinomial.dist(100,theta)\n","data=dice.random()\n","print(data)#ounts for 100 rolls\n","alpha = np.ones(len(data),float)\n","print(\"MAP=\",(data+alpha)/np.sum(data+alpha))\n","#no we throws the dice 10000 times\n","dice = pm.Multinomial.dist(100000,theta)\n","data=dice.random()\n","print(data)#counts for 100000 rolls\n","print(\"MAP=\",(data+alpha)/np.sum(data+alpha))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[10. 15. 24. 30. 14.  7.]\n","MAP= [0.10377358 0.1509434  0.23584906 0.29245283 0.14150943 0.0754717 ]\n","[10031. 20208. 20007. 19844. 19934.  9976.]\n","MAP= [0.10031398 0.20207788 0.200068   0.19843809 0.19933804 0.09976401]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7teEzbm5EL-y","colab_type":"code","colab":{}},"source":["? pm.find_MAP"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lCvMrejwEL-0","colab_type":"text"},"source":["## Spam filter with one feature"]},{"cell_type":"code","metadata":{"id":"T2Z_5dOpEL-1","colab_type":"code","colab":{},"outputId":"41738820-545f-435b-a342-5bc5a3d06f11"},"source":["from sklearn.naive_bayes import BernoulliNB\n","import numpy as np\n","X=np.array([[1,1,1,0,0,1,0,0]]).T# 1 Won included, 0 not included\n","y=np.array( [1,1,0,0,1,1,1,0])#1 spam, 0 not spam\n","Xtest=np.array([[1,0]]).T\n","clf = BernoulliNB(alpha=0.0,fit_prior=True)\n","clf.fit(X, y)\n","print(clf.predict_proba(Xtest))\n","print(clf.predict(Xtest))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.25 0.75]\n"," [0.5  0.5 ]]\n","[1 1]\n"],"name":"stdout"},{"output_type":"stream","text":["/home/benavoli/.local/lib/python3.6/site-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n","  'setting alpha = %.1e' % _ALPHA_MIN)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UtPo0Xd2EL-3","colab_type":"code","colab":{},"outputId":"3a382853-a01e-43e2-d2fb-551e27fd730c"},"source":["print(clf.class_count_)\n","print(clf.feature_count_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[3. 5.]\n","[[1.]\n"," [3.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZiwY2VwGEL-6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1600684784421,"user_tz":-60,"elapsed":802,"user":{"displayName":"Erin Khoo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdO4f_E4KEyeRxhVGq1PO_zKRBF2YL4TM75radu5Q=s64","userId":"01297869029474369226"}},"outputId":"aab7fc92-a53a-476d-ecec-c3c525ab8c65"},"source":["# pg. 45\n","\n","from sklearn.naive_bayes import MultinomialNB\n","import numpy as np\n","X=np.array([[1,0],[1,0],[1,0],[0,1],[0,1],[1,0],[0,1],[0,1]])# 1 Won included, 0 not included\n","y=np.array( [1,1,0,0,1,1,1,0])#1 spam, 0 not spam\n","Xtest=np.array([[1,0],[0,1]]).T\n","clf = MultinomialNB(alpha=0.0,fit_prior=True)\n","clf.fit(X, y)\n","print(clf.predict_proba(Xtest))\n","print(clf.predict(Xtest))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[[0.25 0.75]\n"," [0.5  0.5 ]]\n","[1 1]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n","  'setting alpha = %.1e' % _ALPHA_MIN)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HJ0l4AOMEL-7","colab_type":"code","colab":{},"outputId":"ebfae582-cffa-4c38-a331-15a81cdf06d6"},"source":["print(clf.class_count_)\n","print(clf.feature_count_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[3. 5.]\n","[[1. 0.]\n"," [3. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XkD7eBJhEL--","colab_type":"code","colab":{},"outputId":"0be0dde5-65bf-40e4-8305-db81ab612b05"},"source":["# pg. 46\n","\n","from sklearn.naive_bayes import MultinomialNB\n","import numpy as np\n","X=np.array([[1,0],[1,0],[1,0],[0,1],[0,1],[1,0],[0,1],[0,1]])# 1 Won included, 0 not included\n","y=np.array( [1,1,0,0,1,1,1,0])#1 spam, 0 not spam\n","Xtest=np.array([[1,0],[0,1]]).T\n","clf = MultinomialNB(alpha=1.0,fit_prior=True)\n","clf.fit(X, y)\n","print(clf.predict_proba(Xtest))\n","print(clf.predict(Xtest)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.29577465 0.70422535]\n"," [0.45652174 0.54347826]]\n","[1 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ye-P5HiiEL-_","colab_type":"code","colab":{},"outputId":"eef4d7d5-e597-4598-a8ba-ffcb127a68f5"},"source":["from sklearn.naive_bayes import MultinomialNB\n","import numpy as np\n","X=np.array([[1,0],[1,0],[0,1],[0,1],[1,0],[1,0],[1,0],[0,1]])# 1 Won included, 0 not included\n","y=np.array( [1,1,0,0,1,1,1,0])#1 spam, 0 not spam\n","Xtest=np.array([[1,0],[0,1]]).T\n","clf = MultinomialNB(alpha=0.0,fit_prior=True)\n","clf.fit(X, y)\n","print(clf.predict_proba(Xtest))\n","print(clf.predict(Xtest))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[2.00000000e-11 1.00000000e+00]\n"," [1.00000000e+00 3.33333333e-11]]\n","[1 0]\n"],"name":"stdout"},{"output_type":"stream","text":["/home/benavoli/.local/lib/python3.6/site-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n","  'setting alpha = %.1e' % _ALPHA_MIN)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"kW1Fnp5QEL_C","colab_type":"text"},"source":["## Implementation of MultinomialNB from scratch"]},{"cell_type":"code","metadata":{"id":"0oLO2sNWEL_C","colab_type":"code","colab":{},"outputId":"5195fede-a44b-4d3c-9bbc-76ee8314b50a"},"source":["import numpy as np\n","class MultinomialNB(object):\n","    #class constructor\n","    def __init__(self, alpha=1.0):\n","        self.alpha = alpha#set the smoothing parameter\n","    #fit method\n","    def fit(self, X, y):\n","        count_sample = X.shape[0]\n","        split_per_class = [[x for x, t in zip(X, y) if t == c]\n","                    for c in np.unique(y)]\n","        \n","        self.class_log_prior_ = [np.log(len(i) / count_sample) for i in split_per_class]\n","        count = np.array([np.array(i).sum(axis=0) for i in split_per_class]) + self.alpha\n","        self.feature_log_prob_ = np.log(count / count.sum(axis=1)[np.newaxis].T)\n","        \n","    def predict_proba(self, X):\n","        proba= [np.exp((self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_)\n","                for x in X]\n","        prob=[p/np.sum(p) for p in proba]\n","        return np.vstack(prob)     \n","\n","\n","    def predict(self, X):\n","        return np.argmax(self.predict_log_proba(X), axis=1)\n","    \n","X=np.array([[1,0],[1,0],[1,0],[0,1],[0,1],[1,0],[0,1],[0,1]])\n","y=np.array( [1,1,0,0,1,1,1,0])#1 spam, 0 not spam\n","Xtest=np.array([[1,0],[0,1]]).T\n","\n","MNB = MultinomialNB(1) \n","MNB.fit(X,y)\n","MNB.predict_proba(Xtest)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.29577465, 0.70422535],\n","       [0.45652174, 0.54347826]])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"FTB14FW7EL_E","colab_type":"text"},"source":["## Unigram"]},{"cell_type":"code","metadata":{"id":"LWWeUAsyEL_F","colab_type":"code","colab":{},"outputId":"a4b539fc-84fa-45c8-dbda-29decd9ac7c0"},"source":["import nltk as nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","D=[\"Dear John You won 100 euros\", \"Dear Ashley You won a new car\",\\\n","   \"Hi Helen We won the game yesterday Bye\",\"Huge discount for you buy our new clothes Bye\",\n"," \"Thank you for your offer\", \"You won the lottery\",\n"," \"Buy our cruise\",  \"Dear Charlie Your documents are ready Bye\"]\n","Corpus = [word.lower() for word in D]# we make everything lowercase\n","vectorizer=CountVectorizer()\n","R=vectorizer.fit_transform(Corpus).toarray()\n","WordsList=np.array(vectorizer.get_feature_names())\n","print(WordsList)\n","print(R)#tells us which words are present in each email\n","print(np.sum(R,axis=0))#total counts of each word in "],"execution_count":null,"outputs":[{"output_type":"stream","text":["['100' 'are' 'ashley' 'buy' 'bye' 'car' 'charlie' 'clothes' 'cruise'\n"," 'dear' 'discount' 'documents' 'euros' 'for' 'game' 'helen' 'hi' 'huge'\n"," 'john' 'lottery' 'new' 'offer' 'our' 'ready' 'thank' 'the' 'we' 'won'\n"," 'yesterday' 'you' 'your']\n","[[1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0]\n"," [0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n"," [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0]\n"," [0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0]\n"," [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"," [0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]]\n","[1 1 1 2 3 1 1 1 1 3 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 1 4 1 5 2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YBQoSXhKEL_H","colab_type":"code","colab":{},"outputId":"5c01713b-bdbe-4283-d994-60c11f0dd596"},"source":["Counts = np.sum(R,axis=0)\n","#\n","theta = Counts/np.sum(Counts)#MLE estimate of theta\n","#we define a probabilistic model\n","sentence = pm.Multinomial.dist(5,theta)\n","print(sentence.random())\n","print(\">\",WordsList[sentence.random()==1])#generate some random emails with 5 words\n","print(\">\",WordsList[sentence.random()==1])#generate some random emails with 5 words\n","print(\">\",WordsList[sentence.random()==1])#generate some random emails with 5 words"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0.]\n","> ['dear' 'our' 'won' 'you' 'your']\n","> ['euros' 'new' 'our' 'thank' 'you']\n","> ['ashley' 'buy' 'cruise' 'game' 'new']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9sPQl6c7EL_J","colab_type":"text"},"source":["## Bigram "]},{"cell_type":"code","metadata":{"id":"C4mP84ttEL_K","colab_type":"code","colab":{},"outputId":"b4f6bf8d-40af-48af-e4be-ec532022bcac"},"source":["import nltk as nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","D=[\"Dear John You won 100 euros\", \"Dear Ashley You won a new car\",\\\n","   \"Hi Helen We won the game yesterday Bye\",\"Huge discount for you buy our new clothes Bye\",\n"," \"Thank you for your offer\", \"You won the lottery\",\n"," \"Buy our cruise\",  \"Dear Charlie Your documents are ready Bye\"]\n","Corpus = [word.lower() for word in D]# we make everything lowercase\n","vectorizer=CountVectorizer(ngram_range=(1,1))#unigrams\n","R=vectorizer.fit_transform(Corpus).toarray()\n","WordsList=np.array(vectorizer.get_feature_names())\n","\n","vectorizer=CountVectorizer(ngram_range=(2,2))#bigrams\n","R=vectorizer.fit_transform(Corpus).toarray()\n","Bigrams=np.array(vectorizer.get_feature_names())\n","print(Bigrams)\n","Frequencies=np.zeros((WordsList.shape[0],WordsList.shape[0]))\n","for i in range(len(WordsList)):\n","    for j in range(len(WordsList)):\n","        if WordsList[i]+' '+WordsList[j] in Bigrams:\n","            Frequencies[i,j]=Frequencies[i,j]+1\n","\n","     \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['100 euros' 'are ready' 'ashley you' 'buy our' 'charlie your'\n"," 'clothes bye' 'dear ashley' 'dear charlie' 'dear john' 'discount for'\n"," 'documents are' 'for you' 'for your' 'game yesterday' 'helen we'\n"," 'hi helen' 'huge discount' 'john you' 'new car' 'new clothes'\n"," 'our cruise' 'our new' 'ready bye' 'thank you' 'the game' 'the lottery'\n"," 'we won' 'won 100' 'won new' 'won the' 'yesterday bye' 'you buy'\n"," 'you for' 'you won' 'your documents' 'your offer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yO3U509JEL_M","colab_type":"code","colab":{},"outputId":"601ba92a-02d4-4c7d-ed9c-6dd3a49e2d22"},"source":["theta=(Frequencies+0.0001)/np.sum(Frequencies+0.0001,axis=1)[:,None]  #MLE with smoothing \n","word=\"dear\"\n","Sentence=[word]\n","for i in range(5):\n","    ind=np.where((word == WordsList)==True)[0]\n","    word = WordsList[np.where(pm.Multinomial.dist(1,theta[ind,:]).random()==1)[1]][0]\n","    Sentence.append(word)\n","print(Sentence)\n","word=\"hi\"\n","Sentence=[word]\n","for i in range(5):\n","    ind=np.where((word == WordsList)==True)[0]\n","    word = WordsList[np.where(pm.Multinomial.dist(1,theta[ind,:]).random()==1)[1]][0]\n","    Sentence.append(word)\n","print(Sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['dear', 'charlie', 'your', 'documents', 'are', 'ready']\n","['hi', 'helen', 'we', 'won', '100', 'euros']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i8zOVKqIEL_Q","colab_type":"code","colab":{},"outputId":"716bcda4-bbae-490a-edac-89a45e56ce2b"},"source":["WordsList[np.where(pm.Multinomial.dist(1,theta[ind,:]).random()==1)[1]]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['lottery'], dtype='<U9')"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"WWCbrttJEL_S","colab_type":"code","colab":{},"outputId":"70362851-9454-4ffc-d0db-2a5218f9174d"},"source":["np.where(pm.Multinomial.dist(1,theta[ind,:]).random()==1.)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0]), array([7]))"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"code","metadata":{"id":"NP8zlzdKEL_U","colab_type":"code","colab":{},"outputId":"43cb6bdc-98fc-45cd-b2f2-c277763b119f"},"source":["pm.Multinomial.dist(1,theta[ind,:]).random()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"5bLlrM_XEL_X","colab_type":"text"},"source":["## CountVectorizer\n"]},{"cell_type":"code","metadata":{"id":"mhY1zD6HEL_X","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","corpus = ['red','brown','brown','white']\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","print(vectorizer.get_feature_names())\n","\n","print(X.toarray())"],"execution_count":null,"outputs":[]}]}